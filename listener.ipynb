{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f77092ca-b0c0-4a30-9c6e-4843ac130f08",
   "metadata": {},
   "source": [
    "# Brand sentiment tracking with Tweepy and vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff526712-38aa-4fc9-93bb-0df9f151bade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from IPython.display import display, clear_output\n",
    "import tweepy\n",
    "import csv\n",
    "from geopy.geocoders import Nominatim\n",
    "import re\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_colwidth = 150\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb36d7a2-50b2-419a-8814-c23c629ea42f",
   "metadata": {},
   "source": [
    "### Authentication\n",
    "First, make sure you setup a Twitter API, and input your credentials below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d2a7979-d6a6-4718-b96b-42aa82a2b46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCESS_TOKEN = \n",
    "ACCESS_SECRET = \n",
    "CONSUMER_KEY = \n",
    "CONSUMER_SECRET = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc915c89-f7af-4b89-adb5-3cf33b273ebd",
   "metadata": {},
   "source": [
    "### Brand name extraction\n",
    "The streaming API lets you filter based on tracked terms (in this case, the Twitter handle(s) of the brands we're tracking). But sometimes Tweets pass through the filter that aren't actually related the brand(s) we've specified.\n",
    "<br>\n",
    "\n",
    "The function below will let us double-check that we're only storing Tweets that explicitly mention the brand name(s) of interest. And since we're tracking five brands at once, this also will let us filter the dataset later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9239ae1b-4244-4fc1-b238-24eb4d54cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brand(tweet):\n",
    "    tweet = tweet.lower()\n",
    "    brands = ['input brand names here (ex. if you have @companyNorthAmerica and @companyEU, just put \"company\" to aggregate these.)']\n",
    "    for brand in brands:\n",
    "        if brand in tweet:\n",
    "            return brand\n",
    "    else:\n",
    "        return 'NOBRAND' # These will be filtered out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71515582-7140-4da9-8f52-392538ed0a88",
   "metadata": {},
   "source": [
    "### Extract coordinates\n",
    "Tweepy API has a tweet.coordinates attribute; however, this null about 99.99% of the time.\n",
    "<br>\n",
    "\n",
    "Instead, we'll use the location entry from user bios, and try to extract the coordinates using the Geopy Nominatim tool. Nominatim searches text-based locations, then tries to return the coordinates (and the degree of certainty).\n",
    "<br>\n",
    "\n",
    "The location in user bios is an open text entry. So, it could be useful stuff like: (which turns into lat, long, confidence)\n",
    "* Dallas, Texas, USA => (32.7762719, -96.7968559, 0.8841451879795001)\n",
    "* Paris => (48.8566969, 2.3514616, 0.9417101715588673)\n",
    "* 123 Main street, Anytown, USA => ( ###, ###, 0.9999999)\n",
    "<br>\n",
    "\n",
    "But this is Twitter. So there's also plenty of stuff like:\n",
    "* ðŸŒŽ planet earth ðŸŒŽ\n",
    "* ~ Soundcloud link ~\n",
    "* Coachella 2020 :(\n",
    "<br>\n",
    "\n",
    "Because we're trying to track sentiment by location, we will filter out records where no location could be determined. In addition, we'll filter out records where the location confidence is too low; in the function below, I've abitrarily chosen 70% confidence, but this could be adjusted as needed.\n",
    "<br>\n",
    "\n",
    "NOTE: If you need to extract other attributes besides just lat/long, you can do so in the function below. I ended up using 'Continent' and 'Country' as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be9f8099-919a-4eb0-98d3-576be2512eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_coords(location):\n",
    "    locator = Nominatim(user_agent = \"myGeocoder\")\n",
    "    location = locator.geocode(location)\n",
    "    location\n",
    "    if location == None or location.raw['importance'] < 0.70:\n",
    "        return 'NOTFOUND' # These will be filtered out.\n",
    "    else:\n",
    "        return location.latitude, location.longitude"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c980a4-f6bc-47ea-8ca0-3c5de9089dfa",
   "metadata": {},
   "source": [
    "### Sentiment extraction\n",
    "Now for the main event: extracting sentiment.\n",
    "<br>\n",
    "\n",
    "The first thing we need to do is clean up the text a bit. We'll drop URL's from the text, as well as retweet prefixes (ex. \"RT @Account: tweet text\"). We'll still keep retweets, the rationale being that a person Canada retweeting a tweet originating in Europe is still reflective of the sentiment of that person in Canada.\n",
    "<br>\n",
    "\n",
    "Next, vaderSentiment. This is an open source sentiment analysis tool boasting a classification accuracy of 84%. It's specifically developed for social media use (which is why we won't drop things like emojis: vaderSentiment is designed to take those into account, too).\n",
    "<br>\n",
    "\n",
    "vaderSentiment returns postive, negative, neutral, and compound scores. We'll use the compound, which is described on GitHub as a \"normalized, weighted composite score\" of the other three. \n",
    "\n",
    "To learn more about vaderSentiment, check out: https://github.com/cjhutto/vaderSentiment#about-the-scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13e40d10-3772-4b53-b42b-b0fef80a45a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove URLS \n",
    "    url = re.search(\"(?P<url>https?://[^\\s]+)\", text)\n",
    "    if url != None:\n",
    "        text= text.replace(url.group('url'),'')     \n",
    "    # Drop RT @XYZ\n",
    "    if text[:2] == 'RT':\n",
    "        drop = text.split(' ')[0] + ' ' + text.split(' ')[1]\n",
    "        text = text.replace(drop,'')\n",
    "    return text\n",
    "\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "def vader_senti(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb1cb89-3acd-483d-b5bd-0993e177a14b",
   "metadata": {},
   "source": [
    "### Brand Sentiment Streaming\n",
    "Now we can set up the streaming class. For this project, I followed about 20 Twitter handles related to 5 companies (which I've redacted from this notebook, because while I highly doubt there's any grounds for a cease and desist here, I don't really want to find out). \n",
    "<br>\n",
    "Last\n",
    "The Tweepy StreamListener will track content related to all of the Twitter handles mentioned. We'll filter to English (since that's the language our sentiment extracting tool uses). \n",
    "<br>\n",
    "\n",
    "The on_status method is where we call the feature extractions using the functions above. This is also where we can establish a \"filtration hiearchy\"; in other words, where we decide what to write to our .txt file. As defined previously, we'll ignore (i.e. not write to the .txt file) Tweets that don't have an identifiable brand mentioned, or coordinates that can be identified.\n",
    "<br>\n",
    "\n",
    "Last, the on_error and on_timeout methods: These are just a couple of methods to keep the stream running in the event that an error occurs, rather than killing the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d24c899e-6765-4bbc-bfed-cbdf9b35c70a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define brands here\n",
    "brand1 = ['brand1handle1','brand1handle2']\n",
    "brand2 = ['brand2handl1','brand2handle2']\n",
    "all_brands = brand1 + brand2\n",
    "\n",
    "class MyStreamListener(tweepy.StreamListener):\n",
    "    def __init__(self, api):\n",
    "        self.api = api\n",
    "        self.me = api.me()\n",
    "        \n",
    "    def on_status(self, tweet):\n",
    "        \n",
    "        # Ignore tweets w/no location data \n",
    "        if tweet.user.location != None:\n",
    "            \n",
    "            # Ignore tweets w/no brand clearly mentioned\n",
    "            brand = get_brand(tweet.text)\n",
    "            if brand != 'NOBRAND':\n",
    "                \n",
    "                # Ignore tweets with no identifiable coordinates\n",
    "                coord_extract = extract_coords(tweet.user.location)\n",
    "                time.sleep(1) # to prevent Nominatim timeout\n",
    "                if coord_extract != 'NOTFOUND':\n",
    "                    \n",
    "                    # Extract sentiment\n",
    "                    text_clean = clean_text(tweet.text)\n",
    "                    senti = vader_senti(text_clean)\n",
    "                    \n",
    "                    # Write output to .txt\n",
    "                    rec = [brand, tweet.created_at, tweet.user.location, \n",
    "                           tweet.text, coord_extract, senti]     \n",
    "                    \n",
    "                    with open('data/stream_out.txt', 'a') as f:\n",
    "                        writer = csv.writer(f)\n",
    "                        writer.writerow(rec)\n",
    "    \n",
    "    def on_error(self, status_code):\n",
    "        print('Status code error')\n",
    "        return True # Don't kill the stream\n",
    "\n",
    "    def on_timeout(self):\n",
    "        print('Timeout')\n",
    "        return True # Don't kill the stream. Seriously, don't kill it. I've worked so hard :(\n",
    "\n",
    "# Authenticate to Twitter\n",
    "auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "# Create API object\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
    "\n",
    "# Setup listener\n",
    "tweets_listener = MyStreamListener(api)\n",
    "stream = tweepy.Stream(api.auth, tweets_listener)\n",
    "stream.filter(track = all_brands , languages=[\"en\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc662f8-21a0-428d-a9be-1d43a3608ff1",
   "metadata": {},
   "source": [
    "### Boom, you did it.\n",
    "\n",
    "Have a drink. Make yourself a snack. Give your grandma a call."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
